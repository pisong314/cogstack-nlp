{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create and use a (core) component with medcat2\n",
    "\n",
    "The overall process is quite simple:\n",
    "- Implement and extend `CoreComponent`\n",
    "- Specify the `CoreComponentType`\n",
    "- Register the component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for init args\n",
    "from typing import Optional, Any\n",
    "\n",
    "from medcat2.tokenizing.tokenizers import BaseTokenizer\n",
    "from medcat2.vocab import Vocab\n",
    "from medcat2.cdb.cdb import CDB\n",
    "# for the component itself\n",
    "from medcat2.components.types import AbstractCoreComponent, CoreComponentType\n",
    "from medcat2.tokenizing.tokens import MutableDocument, MutableEntity\n",
    "from medcat2.components.ner.vocab_based_annotator import maybe_annotate_name\n",
    "\n",
    "# for the randomness\n",
    "import random\n",
    "\n",
    "\n",
    "class RNG:\n",
    "\n",
    "    def __init__(self, min: int, mean: int, max: int, std: float):\n",
    "        self.min = min\n",
    "        self.mean = mean\n",
    "        self.max = max\n",
    "        self.std = std\n",
    "\n",
    "    def get(self):\n",
    "        num = int(random.normalvariate(self.mean, self.std))\n",
    "        return min(max(self.min, num), self.max)\n",
    "\n",
    "\n",
    "class RandomNER(AbstractCoreComponent):\n",
    "    # NOTE: NEED TO IMPLEMENT\n",
    "    name = \"RANDOM_NER\"\n",
    "\n",
    "    # NOTE: NEED TO IMPLEMENT \n",
    "    # the arguments provide to the init method in order\n",
    "    @classmethod\n",
    "    def get_init_args(cls, tokenizer: BaseTokenizer, cdb: CDB, vocab: Vocab,\n",
    "                      model_load_path: Optional[str]) -> list[Any]:\n",
    "        return [tokenizer, cdb]\n",
    "\n",
    "    # NOTE: NEED TO IMPLEMENT\n",
    "    # the keyword arguments to the init method\n",
    "    @classmethod\n",
    "    def get_init_kwargs(cls, tokenizer: BaseTokenizer, cdb: CDB, vocab: Vocab,\n",
    "                        model_load_path: Optional[str]) -> dict[str, Any]:\n",
    "        return {}\n",
    "\n",
    "    # NOTE: NEED TO IMPLEMENT\n",
    "    # you can specify whatever init args as long as you define them above\n",
    "    def __init__(self, tokenizer: BaseTokenizer, cdb: CDB):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cdb = cdb\n",
    "\n",
    "        # this is just for the randomness to kind of make sense\n",
    "        # i.e create an entity for every 10 tokens\n",
    "        self.tkns_per_entity = 10\n",
    "        # random number generator for length of the entity (in tokens)\n",
    "        self.rng_len = RNG(\n",
    "            min=1, mean=4, max=8, std=2\n",
    "        )\n",
    "\n",
    "    # NOTE: NEED TO IMPLEMENT\n",
    "    # the type of core component\n",
    "    def get_type(self) -> CoreComponentType:\n",
    "        return CoreComponentType.ner\n",
    "\n",
    "    # NOTE: NEED TO IMPLEMENT\n",
    "    def __call__(self, doc: MutableDocument) -> MutableDocument:\n",
    "        \"\"\"Detect candidates for concepts - linker will then be able\n",
    "        to do the rest. It adds `entities` to the doc.entities and each\n",
    "        entity can have the entity.link_candidates - that the linker\n",
    "        will resolve.\n",
    "\n",
    "        Args:\n",
    "            doc (MutableDocument):\n",
    "                Spacy document to be annotated with named entities.\n",
    "\n",
    "        Returns:\n",
    "            doc (MutableDocument):\n",
    "                Spacy document with detected entities.\n",
    "        \"\"\"\n",
    "        num_tokens = len(list(doc))\n",
    "        num_ents = num_tokens // self.tkns_per_entity\n",
    "\n",
    "        start_tkn_indices = sorted([random.randint(0, num_tokens - 3)\n",
    "                                    for _ in range(num_ents)])\n",
    "        end_tkn_indices = [min(start + self.rng_len.get(), num_tokens - 2)\n",
    "                           for start in start_tkn_indices]\n",
    "        choose_from = list(self.cdb.name2info.keys())\n",
    "        chosen_name = [random.choice(choose_from) for _ in start_tkn_indices]\n",
    "        for tkn_start_idx, tkn_end_idx, linked_name in zip(start_tkn_indices, end_tkn_indices, chosen_name):\n",
    "            char_start_idx = doc[tkn_start_idx].base.char_index\n",
    "            # NOTE: can only do this since we're never selecting the last token\n",
    "            char_end_idx = doc[tkn_end_idx + 1].base.char_index\n",
    "            cur_tokens = doc.get_tokens(char_start_idx, char_end_idx)\n",
    "            # NOTE: the get_tokens method will only return a MutableEntity if it's been set,\n",
    "            #       but nothing should be set before the NER component runs, so it should be\n",
    "            #       safe to assume that these are all lists of tokens\n",
    "\n",
    "            # this checks the config (i.e length and stuff) and then annotes\n",
    "            maybe_annotate_name(self.tokenizer, linked_name, cur_tokens, doc, self.cdb, self.cdb.config)\n",
    "        return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering the component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medcat2.components.types import register_core_component\n",
    "register_core_component(CoreComponentType.ner, RandomNER.name, RandomNER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using custom component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training was enabled during inference. It was automatically disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab (should be empty): {}\n",
      "CDB cui2info {'C01': CUIInfo(cui='C01', preferred_name='CONCEPT1', names={'CONCEPT1'}, subnames={'1', 'concept'}, type_ids=['T1'], description='Concept 1 description', original_names={'CONCEPT1'}, tags=[], group=None, in_other_ontology={'ontologies': {'ONT1'}}, count_train=0, context_vectors=None, average_confidence=0.0), 'C02': CUIInfo(cui='C02', preferred_name='CONCEPT2', names={'CONCEPT2'}, subnames={'concept', '2'}, type_ids=['T1'], description='Concept 2 description', original_names={'CONCEPT2'}, tags=[], group=None, in_other_ontology={'ontologies': {'ONT1'}}, count_train=0, context_vectors=None, average_confidence=0.0)}\n",
      "CDB name2info {'C01': CUIInfo(cui='C01', preferred_name='CONCEPT1', names={'CONCEPT1'}, subnames={'1', 'concept'}, type_ids=['T1'], description='Concept 1 description', original_names={'CONCEPT1'}, tags=[], group=None, in_other_ontology={'ontologies': {'ONT1'}}, count_train=0, context_vectors=None, average_confidence=0.0), 'C02': CUIInfo(cui='C02', preferred_name='CONCEPT2', names={'CONCEPT2'}, subnames={'concept', '2'}, type_ids=['T1'], description='Concept 2 description', original_names={'CONCEPT2'}, tags=[], group=None, in_other_ontology={'ontologies': {'ONT1'}}, count_train=0, context_vectors=None, average_confidence=0.0)}\n",
      "Got CAT\n",
      "Verifying the type of component we're using\n",
      "NER: <__main__.RandomNER object at 0x10a47f670>\n",
      "ENTITIES\n",
      "{'acc': 1,\n",
      " 'context_center': [],\n",
      " 'context_left': [],\n",
      " 'context_right': [],\n",
      " 'context_similarity': 1,\n",
      " 'cui': 'C01',\n",
      " 'detected_name': 'CONCEPT1',\n",
      " 'end': 92,\n",
      " 'id': 0,\n",
      " 'meta_anns': {},\n",
      " 'pretty_name': 'CONCEPT1',\n",
      " 'source_value': 'concept2.\\nWe can have a much longer conversation',\n",
      " 'start': 44,\n",
      " 'type_ids': ['T1']}\n",
      "{'acc': 1,\n",
      " 'context_center': [],\n",
      " 'context_left': [],\n",
      " 'context_right': [],\n",
      " 'context_similarity': 1,\n",
      " 'cui': 'C02',\n",
      " 'detected_name': 'CONCEPT2',\n",
      " 'end': 231,\n",
      " 'id': 2,\n",
      " 'meta_anns': {},\n",
      " 'pretty_name': 'CONCEPT2',\n",
      " 'source_value': 'just filler stuff for the concepts so that',\n",
      " 'start': 189,\n",
      " 'type_ids': ['T1']}\n",
      "{'acc': 1,\n",
      " 'context_center': [],\n",
      " 'context_left': [],\n",
      " 'context_right': [],\n",
      " 'context_similarity': 1,\n",
      " 'cui': 'C01',\n",
      " 'detected_name': 'CONCEPT1',\n",
      " 'end': 151,\n",
      " 'id': 1,\n",
      " 'meta_anns': {},\n",
      " 'pretty_name': 'CONCEPT1',\n",
      " 'source_value': 'going to get us',\n",
      " 'start': 136,\n",
      " 'type_ids': ['T1']}\n",
      "{'acc': 1,\n",
      " 'context_center': [],\n",
      " 'context_left': [],\n",
      " 'context_right': [],\n",
      " 'context_similarity': 1,\n",
      " 'cui': 'C01',\n",
      " 'detected_name': 'CONCEPT1',\n",
      " 'end': 247,\n",
      " 'id': 4,\n",
      " 'meta_anns': {},\n",
      " 'pretty_name': 'CONCEPT1',\n",
      " 'source_value': 'we can \"detect\"',\n",
      " 'start': 232,\n",
      " 'type_ids': ['T1']}\n"
     ]
    }
   ],
   "source": [
    "from medcat2.config.config import Config\n",
    "from medcat2.preprocessors.cleaners import NameDescriptor\n",
    "from medcat2.cat import CAT\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# start with a config\n",
    "cnf = Config()\n",
    "# NOTE: the default is to use regex tokenizer\n",
    "# set the new/registered component\n",
    "cnf.components.ner.comp_name = RandomNER.name\n",
    "\n",
    "# creating an empty Vocab - we don't really need it for this demonstration\n",
    "vocab = Vocab()\n",
    "print(\"Vocab (should be empty):\", vocab.vocab)\n",
    "\n",
    "# create a (random!) CDB\n",
    "rndom_concepts = {\n",
    "    \"C01\": (\n",
    "        {\"CONCEPT1\": NameDescriptor(\n",
    "            tokens=[\"CONCEPT\", \"1\"],\n",
    "            snames=[\"concept\", \"1\"],\n",
    "            raw_name=\"CONCEPT1\",\n",
    "            is_upper=True)\n",
    "        }, {\"ONT1\",}, \"Concept 1 description\"\n",
    "    ),\n",
    "    \"C02\": (\n",
    "        {\"CONCEPT2\": NameDescriptor(\n",
    "            tokens=[\"CONCEPT\", \"2\"],\n",
    "            snames=[\"concept\", \"2\"],\n",
    "            raw_name=\"CONCEPT2\",\n",
    "            is_upper=True)\n",
    "        }, {\"ONT1\",}, \"Concept 2 description\"\n",
    "    )\n",
    "}\n",
    "cdb = CDB(cnf)\n",
    "for cui, (names, ontologies, descr) in rndom_concepts.items():\n",
    "    cdb._add_concept(cui=cui, names=names, ontologies=ontologies,\n",
    "                     name_status='P', type_ids=['T1'],\n",
    "                     description=descr, full_build=True)\n",
    "print(\"CDB cui2info\", cdb.cui2info)\n",
    "print(\"CDB name2info\", cdb.cui2info)\n",
    "\n",
    "# creeate CAT\n",
    "cat = CAT(cdb, vocab)\n",
    "print(\"Got CAT\")\n",
    "print(\"Verifying the type of component we're using\")\n",
    "print(\"NER:\", cat._pipeline.get_component(CoreComponentType.ner))\n",
    "\n",
    "text = \"\"\"Some friends are concept1, but most foes is concept2.\n",
    "We can have a much longer conversation about concepts1 and concepts2 which is\n",
    "not going to get us anywhere we are not already.\n",
    "This is just filler stuff for the concepts so that we can \"detect\" multiple ones.\n",
    "\"\"\"\n",
    "\n",
    "ents = cat.get_entities(text)\n",
    "print(\"ENTITIES\")\n",
    "for ent in ents[\"entities\"].values():\n",
    "    pprint(ent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
